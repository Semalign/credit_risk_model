{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac935a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/rag_pipeline.py\n",
    "\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- 1. Load FAISS index + embeddings ---\n",
    "def load_vector_store(store_path=\"vector_store/faiss_index/\"):\n",
    "    index = faiss.read_index(f\"{store_path}faiss.index\")\n",
    "    with open(f\"{store_path}chunks.pkl\", \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "    with open(f\"{store_path}metadata.pkl\", \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    return index, chunks, metadata\n",
    "\n",
    "# --- 2. Load embedding model + generator ---\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "generator = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\", device=0)  # OR mistral-7B, llama2 etc.\n",
    "\n",
    "# --- 3. Retrieval Function ---\n",
    "def retrieve_relevant_chunks(query, index, chunks, metadata, k=5):\n",
    "    query_vec = embedder.encode([query])\n",
    "    D, I = index.search(np.array(query_vec), k)\n",
    "    top_chunks = [chunks[i] for i in I[0]]\n",
    "    top_meta = [metadata[i] for i in I[0]]\n",
    "    return top_chunks, top_meta\n",
    "\n",
    "# --- 4. Prompt Template ---\n",
    "def build_prompt(context, question):\n",
    "    joined_context = \"\\n\\n\".join(context)\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst assistant for CrediTrust. Your job is to answer questions based on real customer complaints.\n",
    "\n",
    "Use only the information in the context below. If the answer is not in the context, say \"I don't have enough information.\"\n",
    "\n",
    "Context:\n",
    "{joined_context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# --- 5. Complete RAG Pipeline ---\n",
    "def answer_query(query, index, chunks, metadata, k=5):\n",
    "    top_chunks, top_meta = retrieve_relevant_chunks(query, index, chunks, metadata, k)\n",
    "    prompt = build_prompt(top_chunks, query)\n",
    "    result = generator(prompt, max_new_tokens=300, do_sample=True)[0][\"generated_text\"]\n",
    "    return result, top_chunks, top_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag_pipeline import load_vector_store, answer_query\n",
    "\n",
    "index, chunks, metadata = load_vector_store()\n",
    "\n",
    "questions = [\n",
    "    \"Why are users unhappy with Buy Now, Pay Later?\",\n",
    "    \"What are the common complaints about credit cards?\",\n",
    "    \"Do savings accounts have frequent fraud issues?\",\n",
    "    \"Why do customers complain about money transfers?\",\n",
    "    \"Are there refund delays reported in personal loans?\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for q in questions:\n",
    "    answer, top_chunks, top_meta = answer_query(q, index, chunks, metadata)\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": answer.strip(),\n",
    "        \"sources\": top_chunks[:2],\n",
    "        \"quality\": \"\",  # Fill in manually (1–5)\n",
    "        \"comments\": \"\"  # Write your judgment here\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "df_eval = pd.DataFrame(results)\n",
    "df_eval.to_markdown(\"report/task3_evaluation.md\", index=False)\n",
    "print(\"✅ Evaluation table saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
